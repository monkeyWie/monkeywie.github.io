<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 3.9.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"monkeywie.github.io",root:"/",scheme:"Muse",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"always",padding:18,offset:12,onmobile:!1},copycode:{enable:!0,show_result:!0,style:null},back2top:{enable:!0,sidebar:!1,scrollpercent:!1},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:null,storage:!0,lazyload:!1,nav:null},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.json"}</script><meta name="description" content="前言平常开发 spark 应用的时候，为了快速验证程序是否正确一般都会设置master为local模式来运行，但是如果想用集群环境来运行的话，就需要打一个 jar 包用spark-submit进行任务提交，但是在开发过程中频繁打 jar 包提交也是一件麻烦事，查阅相关资料之后发现其实可以在本地运行代码的时候指定集群环境来运行，达到快速调试的目的。"><meta name="keywords" content="spark"><meta property="og:type" content="article"><meta property="og:title" content="spark应用调试"><meta property="og:url" content="https://monkeywie.github.io/2020/04/17/spark-application-debug/index.html"><meta property="og:site_name" content="MonkeyWie&#39;s Blog"><meta property="og:description" content="前言平常开发 spark 应用的时候，为了快速验证程序是否正确一般都会设置master为local模式来运行，但是如果想用集群环境来运行的话，就需要打一个 jar 包用spark-submit进行任务提交，但是在开发过程中频繁打 jar 包提交也是一件麻烦事，查阅相关资料之后发现其实可以在本地运行代码的时候指定集群环境来运行，达到快速调试的目的。"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://monkeywie.github.io/2020/04/17/spark-application-debug/2020-04-17-17-29-04.png"><meta property="og:updated_time" content="2020-08-10T10:35:35.670Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="spark应用调试"><meta name="twitter:description" content="前言平常开发 spark 应用的时候，为了快速验证程序是否正确一般都会设置master为local模式来运行，但是如果想用集群环境来运行的话，就需要打一个 jar 包用spark-submit进行任务提交，但是在开发过程中频繁打 jar 包提交也是一件麻烦事，查阅相关资料之后发现其实可以在本地运行代码的时候指定集群环境来运行，达到快速调试的目的。"><meta name="twitter:image" content="https://monkeywie.github.io/2020/04/17/spark-application-debug/2020-04-17-17-29-04.png"><link rel="canonical" href="https://monkeywie.github.io/2020/04/17/spark-application-debug/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>spark应用调试 | MonkeyWie's Blog</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">MonkeyWie's Blog</h1><span class="logo-line-after"><i></i></span></a></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div><a href="https://github.com/monkeyWie/monkeywie.github.io" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://monkeywie.github.io/2020/04/17/spark-application-debug/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="MonkeyWie"><meta itemprop="description" content="记录技术成长的道路"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="MonkeyWie's Blog"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">spark应用调试</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-04-17 13:49:49" itemprop="dateCreated datePublished" datetime="2020-04-17T13:49:49+08:00">2020-04-17</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/大数据/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a> </span></span><span id="/2020/04/17/spark-application-debug/" class="post-meta-item leancloud_visitors" data-flag-title="spark应用调试" title="阅读次数"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="leancloud-visitors-count"></span></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>3.8k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>3 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>平常开发 spark 应用的时候，为了快速验证程序是否正确一般都会设置<code>master</code>为<code>local</code>模式来运行，但是如果想用集群环境来运行的话，就需要打一个 jar 包用<code>spark-submit</code>进行任务提交，但是在开发过程中频繁打 jar 包提交也是一件麻烦事，查阅相关资料之后发现其实可以在本地运行代码的时候指定集群环境来运行，达到快速调试的目的。</p><a id="more"></a><h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><p>每次运行之前还是需要打一个 jar 包，如果有引入 spark 之外的依赖，需要把依赖也打进去，否则会报<code>ClassNotFound</code>.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbt package</span><br></pre></td></tr></table></figure><h2 id="spark-standalone-集群"><a href="#spark-standalone-集群" class="headerlink" title="spark standalone 集群"></a>spark standalone 集群</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">      .setAppName(<span class="string">"test"</span>)</span><br><span class="line">      <span class="comment">//指定spark master地址</span></span><br><span class="line">      .setMaster(<span class="string">"spark://master:7077"</span>)</span><br><span class="line">      <span class="comment">//指定本地jar包路径</span></span><br><span class="line">      .setJars(<span class="type">List</span>(<span class="string">"file:///E:/code/study/scala/spark-demo/target/scala-2.11/spark-demo_2.11-0.1.jar"</span>))</span><br><span class="line">      <span class="comment">//指定本机IP为driver</span></span><br><span class="line">      .setIfMissing(<span class="string">"spark.driver.host"</span>, <span class="string">"192.168.102.142"</span>)</span><br><span class="line"><span class="keyword">val</span> spark = <span class="type">SparkSession</span>.builder()</span><br><span class="line">    .config(conf)</span><br><span class="line">    .getOrCreate()</span><br></pre></td></tr></table></figure><p>这样在直接运行代码就可以直接运行在指定的 spark 集群环境上了。</p><h2 id="spark-on-yarn-集群"><a href="#spark-on-yarn-集群" class="headerlink" title="spark on yarn 集群"></a>spark on yarn 集群</h2><p>这种集群方式稍微有点麻烦，需要先手动把 spark 中的 jar 包上传到 hdfs 中，然后指定 yarn 运行环境的 spark jars 路径。</p><ol><li><p>上传 jar 包至 hdfs<br>把集群中<code>${SPARK_HOME}/jars</code>目录下的所有文件上传到 hdfs 中</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -put ./jars/* /user/spark/share/lib/2.4.5/</span><br></pre></td></tr></table></figure><p><code>注：如果是使用的cdh安装的spark集群，不能使用cdh中的spark目录下的jar包，因为cdh和apache官方提供的jar包不一致，而开发的时候引入的依赖一般都是apache提供的jar包，这样运行的时候会报错，需要自行从apache官网下载对应的spark发行包然后进行上传，总而言之待上传的spark环境需要和本地开发环境保持一致即可。</code></p></li><li><p>编写代码</p></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">val conf = new SparkConf()</span><br><span class="line">      .setAppName(&quot;test&quot;)</span><br><span class="line">      //设置为yarn模式提交</span><br><span class="line">      .setMaster(&quot;yarn&quot;)</span><br><span class="line">      //设置yarn域名(必需，不然job状态一直ACCEPTED)</span><br><span class="line">      .set(&quot;spark.hadoop.yarn.resourcemanager.hostname&quot;, &quot;master&quot;)</span><br><span class="line">      //设置yarn提交地址</span><br><span class="line">      .set(&quot;spark.hadoop.yarn.resourcemanager.address&quot;, &quot;master:8032&quot;)</span><br><span class="line">      //设置stagingDir，用于存放任务运行时的临时文件</span><br><span class="line">      .set(&quot;spark.yarn.stagingDir&quot;, &quot;hdfs://master:8020/user/root/spark/test&quot;)</span><br><span class="line">      //设置yarn jars，填入上一步上传的hdfs地址</span><br><span class="line">      .set(&quot;spark.yarn.jars&quot;, &quot;hdfs://master:8020/user/spark/share/lib/2.4.5/*.jar&quot;)</span><br><span class="line">      //设置本地jar包地址</span><br><span class="line">      .setJars(List(&quot;file:///E:/code/study/scala/spark-demo/target/scala-2.11/spark-demo_2.11-0.1.jar&quot;))</span><br><span class="line">      //指定本机IP为driver</span><br><span class="line">      .setIfMissing(&quot;spark.driver.host&quot;, &quot;192.168.102.142&quot;)</span><br><span class="line">val spark = SparkSession.builder()</span><br><span class="line">    .config(conf)</span><br><span class="line">    .getOrCreate()</span><br></pre></td></tr></table></figure><h2 id="关于-setJars"><a href="#关于-setJars" class="headerlink" title="关于 setJars"></a>关于 setJars</h2><p>前面说了每次运行之前都需要重新构建一次 jar 包，但其实也不一定，这个 jar 包的作用是为了能将参与 spark 运算的<code>匿名函数</code>的反序列化。</p><p>所以在没有修改<code>运算逻辑</code>的时候，可以不需要重新构建 jar 包，举个例子来证明：</p><ol><li>第一次代码如下：</li></ol><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">spark.sparkContext</span><br><span class="line">      .parallelize(<span class="type">List</span>(<span class="string">"hello word"</span>, <span class="string">"test word"</span>, <span class="string">"hello haha"</span>, <span class="string">"ok"</span>))</span><br><span class="line">      .flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line">      .map((_, <span class="number">1</span>))</span><br><span class="line">      .take(<span class="number">10</span>)</span><br><span class="line">      .foreach(kv =&gt; println(kv._1 + <span class="string">":"</span> + kv._2))</span><br></pre></td></tr></table></figure><ol start="2"><li>构建 jar 包</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbt package</span><br></pre></td></tr></table></figure><ol start="3"><li>运行代码</li></ol><p>输出结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">test:1</span><br><span class="line">ok:1</span><br><span class="line">haha:1</span><br><span class="line">hello:2</span><br><span class="line">word:2</span><br></pre></td></tr></table></figure><ol start="4"><li>修改代码，把数据改一改</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">spark.sparkContext</span><br><span class="line">      .parallelize(List(&quot;hello scala&quot;, &quot;test scala&quot;, &quot;hello haha&quot;, &quot;ok&quot;))</span><br><span class="line">      .flatMap(_.split(&quot; &quot;))</span><br><span class="line">      .map((_, 1))</span><br><span class="line">      .countByKey()</span><br><span class="line">      .take(10)</span><br><span class="line">      .foreach(kv =&gt; println(kv._1 + &quot;:&quot; + kv._2))</span><br></pre></td></tr></table></figure><ol start="5"><li>不重新构建 jar 包，直接运行</li></ol><p>结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">test:1</span><br><span class="line">scala:2</span><br><span class="line">ok:1</span><br><span class="line">haha:1</span><br><span class="line">hello:2</span><br></pre></td></tr></table></figure><p>可以发现没有重新构建 jar 包，结果也边了，说明是运行的刚刚修改的代码。</p><ol start="6"><li>修改算子运行</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">spark.sparkContext</span><br><span class="line">      .parallelize(List(&quot;hello scala&quot;, &quot;test scala&quot;, &quot;hello haha&quot;, &quot;ok&quot;))</span><br><span class="line">      .flatMap(_.split(&quot; &quot;))</span><br><span class="line">      .map((_, 2)) //注意这里从1改成了2</span><br><span class="line">      .countByKey()</span><br><span class="line">      .take(10)</span><br><span class="line">      .foreach(kv =&gt; println(kv._1 + &quot;:&quot; + kv._2))</span><br></pre></td></tr></table></figure><p>不重新构建 jar 包，直接运行，结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">test:1</span><br><span class="line">scala:2</span><br><span class="line">ok:1</span><br><span class="line">haha:1</span><br><span class="line">hello:2</span><br></pre></td></tr></table></figure><p>计算结果和之前的一样，没有发生变化，说明在计算的时候，节点是以 jar 中编译好的 class 进行计算。</p><ol start="7"><li>继续测试</li></ol><p>修改代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">spark.sparkContext</span><br><span class="line">      .parallelize(List(&quot;hello scala&quot;, &quot;test scala&quot;, &quot;hello haha&quot;, &quot;ok&quot;))</span><br><span class="line">      .flatMap(_.split(&quot; &quot;))</span><br><span class="line">      .map((_, 2))</span><br><span class="line">      .countByKey()</span><br><span class="line">      .take(10)</span><br><span class="line">      .foreach(kv =&gt; println(kv._1 + &quot;=&quot; + kv._2)) //注意这里将:换成了=</span><br></pre></td></tr></table></figure><p>直接运行，结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">test=1</span><br><span class="line">scala=2</span><br><span class="line">ok=1</span><br><span class="line">haha=1</span><br><span class="line">hello=2</span><br></pre></td></tr></table></figure><p>可以看到结果发生变化了，同样是匿名函数的实现修改，为什么这里又可以直接生效呢，接着往下。</p><h2 id="setJars-原理"><a href="#setJars-原理" class="headerlink" title="setJars 原理"></a>setJars 原理</h2><p>通过上面的示例，可以指定在这个例子中 spark 从 jar 包里主要拿到下面两个<code>匿名函数</code>反序列化之后的类</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">.flatMap(_.split(&quot; &quot;))</span><br><span class="line">.map((_, 1))</span><br></pre></td></tr></table></figure><p>把 jar 包打开看一看，里面有三个内部类，分别对应代码中的三个<code>匿名函数</code><br><img src="/2020/04/17/spark-application-debug/2020-04-17-17-29-04.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">//main$1.class</span><br><span class="line">.flatMap(_.split(&quot; &quot;))</span><br><span class="line">//main$2.class</span><br><span class="line">.map((_, 1))</span><br><span class="line">//main$3.class</span><br><span class="line">.foreach(kv =&gt; println(kv._1 + &quot;:&quot; + kv._2))</span><br></pre></td></tr></table></figure><p>在将 rdd 分发到各个计算节点时，都是通过 jar 包中的 class 来<code>反序列化</code>出对应的<code>匿名函数</code>，所以在没有重新构建 jar 包的情况下修改代码不会生效，但是由于<code>.foreach(kv =&gt; println(kv._1 + &quot;:&quot; + kv._2))</code>在<code>take()</code>方法之后调用，take 这个方法是将计算结果取回到<code>driver</code>中，是使用本地运行时编译的 class，所以这里代码修改的话不需要重新构建 jar 也能及时生效。</p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>本来只是想要通过代码直接提交任务至 spark 集群环境，却意外研究了<code>setJars</code>相关的知识，让我对 spark 计算过程有了更深刻的了解，甚是美哉。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://stackoverflow.com/a/52164371/8129004" target="_blank" rel="noopener">https://stackoverflow.com/a/52164371/8129004</a></p></div><div class="reward-container"><div>如果觉得本文对您有帮助，可以请我喝一杯咖啡☕</div><button onclick='var qr=document.getElementById("qr");qr.style.display="none"===qr.style.display?"block":"none"'>打赏</button><div id="qr" style="display:none"><div style="display:inline-block"><img src="/images/wechatpay.png" alt="MonkeyWie 微信支付"><p>微信支付</p></div><div style="display:inline-block"><img src="/images/alipay.jpg" alt="MonkeyWie 支付宝"><p>支付宝</p></div></div></div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者： </strong>MonkeyWie</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="https://monkeywie.github.io/2020/04/17/spark-application-debug/" title="spark应用调试">https://monkeywie.github.io/2020/04/17/spark-application-debug/</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><footer class="post-footer"><div class="post-tags"><a href="/tags/spark/" rel="tag"># spark</a></div><div class="post-nav"><div class="post-nav-item"><a href="/2020/04/14/cdh6-2-install/" rel="prev" title="CDH6.2离线安装"><i class="fa fa-chevron-left"></i> CDH6.2离线安装</a></div><div class="post-nav-item"><a href="/2020/04/23/chrome-clear-hsts/" rel="next" title="chrome清除HSTS记录">chrome清除HSTS记录 <i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments"><script src="https://utteranc.es/client.js" repo="monkeyWie/monkeywie.github.io" issue-term="pathname" theme="github-light" crossorigin="anonymous" async></script></div><script>window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#前言"><span class="nav-number">1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#准备"><span class="nav-number">2.</span> <span class="nav-text">准备</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#spark-standalone-集群"><span class="nav-number">3.</span> <span class="nav-text">spark standalone 集群</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#spark-on-yarn-集群"><span class="nav-number">4.</span> <span class="nav-text">spark on yarn 集群</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#关于-setJars"><span class="nav-number">5.</span> <span class="nav-text">关于 setJars</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#setJars-原理"><span class="nav-number">6.</span> <span class="nav-text">setJars 原理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#后记"><span class="nav-number">7.</span> <span class="nav-text">后记</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考"><span class="nav-number">8.</span> <span class="nav-text">参考</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><p class="site-author-name" itemprop="name">MonkeyWie</p><div class="site-description" itemprop="description">记录技术成长的道路</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">47</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">11</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">47</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/monkeyWie" title="GitHub → https://github.com/monkeyWie" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:liwei-8466@gmail.com" title="E-Mail → mailto:liwei-8466@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a></span></div><div class="cc-license motion-element" itemprop="license"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a></div></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2020</span> <span class="with-love"><i class="fa fa-user"></i> </span><span class="author" itemprop="copyrightHolder">MonkeyWie</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-area-chart"></i> </span><span title="站点总字数">136k</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span title="站点阅读时长">2:04</span></div><div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动</div><script>(function() {
    function leancloudSelector(url) {
      url = encodeURI(url);
      return document.getElementById(url).querySelector('.leancloud-visitors-count');
    }

    function addCount(Counter) {
      var visitors = document.querySelector('.leancloud_visitors');
      var url = decodeURI(visitors.id);
      var title = visitors.dataset.flagTitle;

      Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({ url })))
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length > 0) {
            var counter = results[0];
            leancloudSelector(url).innerText = counter.time + 1;
            Counter('put', '/classes/Counter/' + counter.objectId, { time: { '__op': 'Increment', 'amount': 1 } })
              .catch(error => {
                console.error('Failed to save visitor count', error);
              });
          } else {
              leancloudSelector(url).innerText = 'Counter not initialized! More info at console err msg.';
              console.error('ATTENTION! LeanCloud counter has security bug, see how to solve it here: https://github.com/theme-next/hexo-leancloud-counter-security. \n However, you can still use LeanCloud without security, by setting `security` option to `false`.');
            
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }

    function showTime(Counter) {
      var visitors = document.querySelectorAll('.leancloud_visitors');
      var entries = [...visitors].map(element => {
        return decodeURI(element.id);
      });

      Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({ url: { '$in': entries } })))
        .then(response => response.json())
        .then(({ results }) => {
          for (let url of entries) {
            let target = results.find(item => item.url === url);
            leancloudSelector(url).innerText = target ? target.time : 0;
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }

    let { app_id, app_key, server_url } = {"enable":true,"app_id":"JJB6KD9eEdOLCiTAjiXkkPmL-gzGzoHsz","app_key":"xatpuWFn8w0EkkBJ4lbJlT62","server_url":null,"security":true};
    function fetchData(api_server) {
      var Counter = (method, url, data) => {
        return fetch(`${api_server}/1.1${url}`, {
          method,
          headers: {
            'X-LC-Id'     : app_id,
            'X-LC-Key'    : app_key,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      if (CONFIG.page.isPost) {
        if (CONFIG.hostname !== location.hostname) return;
        addCount(Counter);
      } else if (document.querySelectorAll('.post-title-link').length >= 1) {
        showTime(Counter);
      }
    }

    let api_server = app_id.slice(-9) !== '-MdYXbMMI' ? server_url : `https://${app_id.slice(0, 8).toLowerCase()}.api.lncldglobal.com`;

    if (api_server) {
      fetchData(api_server);
    } else {
      fetch('https://app-router.leancloud.cn/2/route?appId=' + app_id)
        .then(response => response.json())
        .then(({ api_server }) => {
          fetchData('https://' + api_server);
        });
    }
  })();</script></div></footer></div><script src="/lib/anime.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script></body></html>